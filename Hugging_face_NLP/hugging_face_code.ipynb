{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "                                              0.0/486.2 kB ? eta -:--:--\n",
      "                                              10.2/486.2 kB ? eta -:--:--\n",
      "     --                                    30.7/486.2 kB 262.6 kB/s eta 0:00:02\n",
      "     ---                                   41.0/486.2 kB 219.4 kB/s eta 0:00:03\n",
      "     -----                                 71.7/486.2 kB 357.2 kB/s eta 0:00:02\n",
      "     -------                               92.2/486.2 kB 403.5 kB/s eta 0:00:01\n",
      "     --------                             112.6/486.2 kB 364.4 kB/s eta 0:00:02\n",
      "     --------------                       194.6/486.2 kB 562.0 kB/s eta 0:00:01\n",
      "     -----------------                    235.5/486.2 kB 627.5 kB/s eta 0:00:01\n",
      "     --------------------                 276.5/486.2 kB 630.9 kB/s eta 0:00:01\n",
      "     -----------------------------        399.4/486.2 kB 831.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 486.2/486.2 kB 951.9 kB/s eta 0:00:00\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "                                              0.0/81.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 81.4/81.4 kB ? eta 0:00:00\n",
      "Collecting transformers[sentencepiece]\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "                                              0.0/7.2 MB ? eta -:--:--\n",
      "     -                                        0.3/7.2 MB 6.3 MB/s eta 0:00:02\n",
      "     --                                       0.5/7.2 MB 6.6 MB/s eta 0:00:02\n",
      "     ---                                      0.6/7.2 MB 3.8 MB/s eta 0:00:02\n",
      "     ----                                     0.7/7.2 MB 3.9 MB/s eta 0:00:02\n",
      "     -----                                    1.1/7.2 MB 4.5 MB/s eta 0:00:02\n",
      "     --------                                 1.4/7.2 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------                                1.7/7.2 MB 5.3 MB/s eta 0:00:02\n",
      "     -----------                              2.1/7.2 MB 5.5 MB/s eta 0:00:01\n",
      "     -------------                            2.4/7.2 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------                          2.7/7.2 MB 5.9 MB/s eta 0:00:01\n",
      "     -----------------                        3.1/7.2 MB 6.0 MB/s eta 0:00:01\n",
      "     -------------------                      3.4/7.2 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------                    3.8/7.2 MB 6.2 MB/s eta 0:00:01\n",
      "     -----------------------                  4.1/7.2 MB 6.4 MB/s eta 0:00:01\n",
      "     -------------------------                4.5/7.2 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------------              4.9/7.2 MB 6.6 MB/s eta 0:00:01\n",
      "     -----------------------------            5.3/7.2 MB 6.8 MB/s eta 0:00:01\n",
      "     -------------------------------          5.7/7.2 MB 6.9 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.2/7.2 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.6/7.2 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.2/7.2 MB 7.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.2/7.2 MB 7.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from datasets) (1.25.0)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-12.0.1-cp311-cp311-win_amd64.whl (21.5 MB)\n",
      "                                              0.0/21.5 MB ? eta -:--:--\n",
      "                                              0.4/21.5 MB 8.3 MB/s eta 0:00:03\n",
      "     -                                        0.8/21.5 MB 8.6 MB/s eta 0:00:03\n",
      "     --                                       1.4/21.5 MB 9.7 MB/s eta 0:00:03\n",
      "     ---                                      1.8/21.5 MB 10.6 MB/s eta 0:00:02\n",
      "     ----                                     2.3/21.5 MB 10.2 MB/s eta 0:00:02\n",
      "     -----                                    2.8/21.5 MB 10.4 MB/s eta 0:00:02\n",
      "     ------                                   3.3/21.5 MB 10.5 MB/s eta 0:00:02\n",
      "     -------                                  3.8/21.5 MB 10.5 MB/s eta 0:00:02\n",
      "     -------                                  4.3/21.5 MB 10.5 MB/s eta 0:00:02\n",
      "     ---------                                4.9/21.5 MB 10.7 MB/s eta 0:00:02\n",
      "     ---------                                5.3/21.5 MB 10.6 MB/s eta 0:00:02\n",
      "     -----------                              5.9/21.5 MB 10.8 MB/s eta 0:00:02\n",
      "     ------------                             6.5/21.5 MB 10.9 MB/s eta 0:00:02\n",
      "     -------------                            7.0/21.5 MB 11.0 MB/s eta 0:00:02\n",
      "     --------------                           7.6/21.5 MB 11.0 MB/s eta 0:00:02\n",
      "     ---------------                          8.1/21.5 MB 11.0 MB/s eta 0:00:02\n",
      "     ----------------                         8.6/21.5 MB 11.0 MB/s eta 0:00:02\n",
      "     -----------------                        9.1/21.5 MB 11.0 MB/s eta 0:00:02\n",
      "     -----------------                        9.6/21.5 MB 11.0 MB/s eta 0:00:02\n",
      "     ------------------                      10.2/21.5 MB 11.0 MB/s eta 0:00:02\n",
      "     -------------------                     10.7/21.5 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------                    11.2/21.5 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------                   11.7/21.5 MB 11.1 MB/s eta 0:00:01\n",
      "     ----------------------                  12.1/21.5 MB 11.1 MB/s eta 0:00:01\n",
      "     ----------------------                  12.6/21.5 MB 11.1 MB/s eta 0:00:01\n",
      "     -----------------------                 13.1/21.5 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------                13.6/21.5 MB 11.1 MB/s eta 0:00:01\n",
      "     -------------------------               14.0/21.5 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------------------              14.5/21.5 MB 10.9 MB/s eta 0:00:01\n",
      "     ---------------------------             15.0/21.5 MB 10.9 MB/s eta 0:00:01\n",
      "     ----------------------------            15.5/21.5 MB 10.9 MB/s eta 0:00:01\n",
      "     -----------------------------           16.0/21.5 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------          16.5/21.5 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------          17.0/21.5 MB 10.7 MB/s eta 0:00:01\n",
      "     -------------------------------         17.5/21.5 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------------------------        18.0/21.5 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------------       18.5/21.5 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------------      19.0/21.5 MB 10.7 MB/s eta 0:00:01\n",
      "     -----------------------------------     19.4/21.5 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------    19.9/21.5 MB 10.6 MB/s eta 0:00:01\n",
      "     -------------------------------------   20.4/21.5 MB 10.6 MB/s eta 0:00:01\n",
      "     -------------------------------------   20.9/21.5 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  21.5/21.5 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 21.5/21.5 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "                                              0.0/110.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 110.5/110.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pandas in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from datasets) (2.29.0)\n",
      "Collecting tqdm>=4.62.1 (from datasets)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.2.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "                                              0.0/134.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 134.3/134.3 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting fsspec[http]>=2021.11.1 (from datasets)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "                                              0.0/163.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 163.8/163.8 kB ? eta 0:00:00\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "                                              0.0/317.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 317.2/317.2 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "                                              0.0/236.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 236.8/236.8 kB 14.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from datasets) (6.0)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Collecting regex!=2019.12.17 (from transformers[sentencepiece])\n",
      "  Downloading regex-2023.6.3-cp311-cp311-win_amd64.whl (268 kB)\n",
      "                                              0.0/268.0 kB ? eta -:--:--\n",
      "     ------------------------------------- 268.0/268.0 kB 17.2 MB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece])\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "                                              0.0/3.5 MB ? eta -:--:--\n",
      "     ---                                      0.3/3.5 MB 10.2 MB/s eta 0:00:01\n",
      "     --------                                 0.7/3.5 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------                           1.2/3.5 MB 9.7 MB/s eta 0:00:01\n",
      "     --------------------                     1.7/3.5 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------------               2.3/3.5 MB 10.5 MB/s eta 0:00:01\n",
      "     --------------------------------         2.8/3.5 MB 10.5 MB/s eta 0:00:01\n",
      "     -------------------------------------    3.2/3.5 MB 10.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.5/3.5 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.3.1 (from transformers[sentencepiece])\n",
      "  Downloading safetensors-0.3.1-cp311-cp311-win_amd64.whl (263 kB)\n",
      "                                              0.0/263.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 263.7/263.7 kB 7.9 MB/s eta 0:00:00\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "                                              0.0/977.5 kB ? eta -:--:--\n",
      "     ---------------                        389.1/977.5 kB 8.1 MB/s eta 0:00:01\n",
      "     ----------------------------           737.3/977.5 kB 7.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 977.5/977.5 kB 8.9 MB/s eta 0:00:00\n",
      "Collecting protobuf<=3.20.3 (from transformers[sentencepiece])\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "                                              0.0/162.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 162.1/162.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n",
      "                                              0.0/60.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.2/60.2 kB ? eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\miniconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, xxhash, tqdm, regex, pyarrow, protobuf, multidict, fsspec, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.13.1 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 fsspec-2023.6.0 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 protobuf-3.20.3 pyarrow-12.0.1 regex-2023.6.3 responses-0.18.0 safetensors-0.3.1 sentencepiece-0.1.99 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.30.2 xxhash-3.2.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/14824/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d828dced2add4d889cb46ce5406eecfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets\n",
    "# raw_train_dataset = raw_datasets['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_train_dataset[15]\n",
    "raw_datasets['validation'][87]\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
    "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])\n",
    "type(tokenized_sentences_1)\n",
    "len(raw_datasets['train']['sentence1'])\n",
    "len(raw_datasets['train']['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2879ae1b1bba49dc8d4c3594b8572345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30876ddcc1b46ac93cd074593a4de6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde46ef64e944687ab6142a759345494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 59, 47, 67, 59, 50, 62, 32]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tokenized_datasets[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c08f5844dbc7703de6ca8cbf6a6f36c3d96d21c5a028823bf89186eed0f6a14c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
